# =====================================================
# NDA REVIEWER v2 - ENVIRONMENT CONFIGURATION
# =====================================================
# Copy this file to .env and fill in your values

# =====================================================
# API KEYS (REQUIRED)
# =====================================================
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# =====================================================
# ENFORCEMENT LEVEL CONFIGURATION
# =====================================================
# Options: Bloody, Balanced, Lenient
# - Bloody: Zero tolerance, flags all issues (critical + high + moderate + low + advisory)
# - Balanced: Professional strictness (critical + high + moderate)
# - Lenient: Only critical issues
ENFORCEMENT_LEVEL=Balanced

# =====================================================
# PASS CONFIGURATION
# =====================================================
# Enable/disable specific passes in the pipeline
ENABLE_PASS_0=true    # Deterministic rules (always recommended)
ENABLE_PASS_1=true    # GPT-5 recall maximization
ENABLE_PASS_2=true    # Claude Sonnet validation
ENABLE_PASS_3=true    # Claude Opus adjudication
ENABLE_PASS_4=true    # Consistency sweep

# Pass 1 (GPT) Configuration
GPT_MODEL=gpt-5                   # Latest model (GPT-5, released August 2025)
GPT_TEMPERATURE=0.1               # Temperature for GPT (0.0-1.0)
GPT_MAX_TOKENS=2000              # Max tokens per GPT call
SKIP_GPT_CONFIDENCE_THRESHOLD=98  # Skip Pass 1 if rule confidence >= this %

# Pass 2 (Sonnet) Configuration
SONNET_MODEL=claude-3-5-sonnet-20241022
SONNET_TEMPERATURE=0.2
SONNET_MAX_TOKENS=1500

# Pass 3 (Opus) Configuration
OPUS_MODEL=claude-3-opus-20240229
OPUS_TEMPERATURE=0.1
OPUS_MAX_TOKENS=2000
OPUS_CONFIDENCE_THRESHOLD=85      # Route to Opus if confidence < this %
OPUS_BATCH_SIZE=5                 # Max violations per Opus batch

# Pass 4 (Consistency) Configuration
CONSISTENCY_CHECK_BANNED_TOKENS=true
CONSISTENCY_CHECK_REQUIRED_CLAUSES=true
CONSISTENCY_CHECK_STYLE=true

# =====================================================
# CACHING CONFIGURATION
# =====================================================
ENABLE_CACHE=true
CACHE_TYPE=semantic               # Options: semantic, redis, memory
CACHE_VALIDATED_ONLY=true         # Only cache items validated by Pass 2+
CONSENSUS_THRESHOLD=90            # Min consensus % required for caching
CACHE_TTL_HOURS=24               # Cache time-to-live in hours

# Redis Configuration (if CACHE_TYPE=redis)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

# FAISS Configuration (if CACHE_TYPE=semantic)
FAISS_INDEX_PATH=./storage/faiss_index.bin
FAISS_DIMENSION=1536              # Embedding dimension
FAISS_NLIST=100                  # Number of clusters for IVF index

# =====================================================
# PERFORMANCE CONFIGURATION
# =====================================================
MAX_CONCURRENT_DOCUMENTS=3        # Max documents to process in parallel
REQUEST_TIMEOUT_SECONDS=120       # Timeout for individual API calls
PIPELINE_TIMEOUT_SECONDS=600      # Total pipeline timeout per document
ENABLE_TELEMETRY=true            # Track performance metrics
TELEMETRY_SAMPLE_RATE=1.0        # Percentage of requests to track (0.0-1.0)

# =====================================================
# RULE ENGINE CONFIGURATION
# =====================================================
RULES_FILE=backend/app/models/rules_v2.yaml
RULE_PATTERN_CACHE=true          # Cache compiled regex patterns
RULE_PARALLEL_PROCESSING=true    # Process rules in parallel
RULE_BATCH_SIZE=10              # Rules to process per batch

# =====================================================
# LOGGING CONFIGURATION
# =====================================================
LOG_LEVEL=INFO                   # Options: DEBUG, INFO, WARNING, ERROR
LOG_FILE=logs/nda_reviewer.log
LOG_MAX_SIZE_MB=100
LOG_BACKUP_COUNT=5
LOG_FORMAT=json                  # Options: json, text

# =====================================================
# SERVER CONFIGURATION
# =====================================================
HOST=0.0.0.0
PORT=8000
WORKERS=4                        # Number of worker processes
RELOAD=false                     # Auto-reload on code changes (dev only)
DEBUG=false                      # Debug mode (never use in production)

# =====================================================
# DOCUMENT PROCESSING
# =====================================================
MAX_DOCUMENT_SIZE_MB=10          # Maximum document size to accept
ALLOWED_EXTENSIONS=.docx,.pdf,.txt,.md
EXTRACT_TABLES=true              # Extract and analyze tables
PRESERVE_FORMATTING=true         # Maintain original formatting in exports
TRACK_CHANGES=true              # Enable track changes in Word exports

# =====================================================
# EXPORT CONFIGURATION
# =====================================================
EXPORT_FORMATS=docx,pdf,json,markdown
DEFAULT_EXPORT_FORMAT=docx
INCLUDE_REDLINES_BY_DEFAULT=true
INCLUDE_SUMMARY_BY_DEFAULT=true
EXPORT_TEMP_DIR=./storage/exports
EXPORT_CLEANUP_HOURS=24         # Delete exports after this many hours

# =====================================================
# SECURITY CONFIGURATION
# =====================================================
ENABLE_CORS=true
CORS_ORIGINS=http://localhost:3000,https://yourdomain.com
MAX_REQUEST_SIZE_MB=20
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS_PER_MINUTE=60
API_KEY_REQUIRED=false          # Set to true for production
API_KEY_HEADER=X-API-Key

# =====================================================
# MONITORING & ALERTS
# =====================================================
ENABLE_MONITORING=true
METRICS_PORT=9090               # Prometheus metrics port
HEALTH_CHECK_PATH=/health
ALERT_ON_ERROR_RATE=0.05       # Alert if error rate > 5%
ALERT_ON_P95_LATENCY_MS=10000  # Alert if P95 latency > 10s
ALERT_WEBHOOK_URL=              # Slack/Discord webhook for alerts

# =====================================================
# DEVELOPMENT SETTINGS
# =====================================================
DEV_MODE=false                  # Enable development features
MOCK_LLM_CALLS=false           # Use mock responses (testing only)
SAVE_LLM_RESPONSES=false       # Save all LLM responses for debugging
RESPONSE_SAVE_DIR=./storage/llm_responses

# =====================================================
# FEATURE FLAGS
# =====================================================
FEATURE_MULTI_MODE_COMPARISON=true    # Compare all 3 modes simultaneously
FEATURE_PATTERN_LEARNING=false        # Learn from validated corrections
FEATURE_CUSTOM_RULES=false           # Allow user-defined rules
FEATURE_BATCH_PROCESSING=true        # Enable batch document processing
FEATURE_WEBHOOK_NOTIFICATIONS=false  # Send webhooks on completion

# =====================================================
# DATABASE CONFIGURATION (Future)
# =====================================================
# DATABASE_URL=postgresql://user:password@localhost:5432/nda_reviewer
# DATABASE_POOL_SIZE=10
# DATABASE_MAX_OVERFLOW=20